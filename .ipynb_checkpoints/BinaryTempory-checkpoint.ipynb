{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing Service Placement for MicroserviceArchitecture in Clouds - Paper\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pprint\n",
    "import operator\n",
    "import random\n",
    "import copy\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gke-onlineboutique-default-pool-db17c72b-snh7': '7436140544.0',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-1d5h': '6979616768.0',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '7339319296.0',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-84r9': '7173533696.0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cores_per_node = 2.0\n",
    "vm_threshold_per_pod = 0.1 # Threshold for reserving sufficient resources for each pod\n",
    "node_available_ram = {'gke-onlineboutique-default-pool-db17c72b-snh7': '7436140544.0',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': '6979616768.0',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '7339319296.0',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': '7173533696.0'}\n",
    "node_available_ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ram_per_pod = 835242393.6\n",
    "node_total_ram = {'gke-onlineboutique-default-pool-db17c72b-snh7': max_ram_per_pod * 10,\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': max_ram_per_pod * 10,\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': max_ram_per_pod * 10,\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': max_ram_per_pod * 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gke-onlineboutique-default-pool-db17c72b-snh7': '0.7923',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-1d5h': '0.7731',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '0.7827',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-84r9': '0.7707'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_available_cpu = {'gke-onlineboutique-default-pool-db17c72b-snh7': '0.7923',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': '0.7731',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '0.7827',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': '0.7707'}\n",
    "node_available_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_pod_resources(resource_dict):\n",
    "    curr_dict = {}\n",
    "    for hosts in resource_dict:\n",
    "        for services in resource_dict[hosts]:\n",
    "            # Pattern: service_name-ID-SubID\n",
    "            split_string = re.split(\"-\", services)\n",
    "            if(len(split_string) == 3):\n",
    "                curr_service = split_string[0]\n",
    "            else:\n",
    "                curr_service = split_string[0] + '-'+ split_string[1]\n",
    "                \n",
    "            curr_dict[curr_service] = format(float(resource_dict[hosts][services]), '.3f')\n",
    "           \n",
    "    return curr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_pod_requests(resource_dict):\n",
    "    curr_dict = {}\n",
    "    for services in resource_dict.keys():\n",
    "        # Pattern: service_name-ID-SubID\n",
    "        split_string = re.split(\"-\", services)\n",
    "        if(len(split_string) == 3):\n",
    "            curr_service = split_string[0]\n",
    "        else:\n",
    "            curr_service = split_string[0] + '-'+ split_string[1]\n",
    "                \n",
    "        curr_dict[curr_service] = format(float(resource_dict[services]), '.3f')\n",
    "\n",
    "    return curr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gke-onlineboutique-default-pool-db17c72b-snh7': {'loadgenerator-88f7dbff5-dwncr': '0.0154'},\n",
       " 'gke-onlineboutique-default-pool-db17c72b-1d5h': {'cartservice-6fc79c6d86-q784f': '0.0234',\n",
       "  'shippingservice-5f4d856dc-7rxzk': '0.0434',\n",
       "  'paymentservice-5bdd645d9f-jqmp4': '0.0834',\n",
       "  'checkoutservice-7c95787547-kcqpr': '0.1234'},\n",
       " 'gke-onlineboutique-default-pool-db17c72b-dw0s': {'emailservice-799966ff9f-fdscz': '0.0434',\n",
       "  'productcatalogservice-7ffbf4fbf5-rtw8d': '0.0934'},\n",
       " 'gke-onlineboutique-default-pool-db17c72b-84r9': {'currencyservice-67674dbdf7-mx8xc': '0.0634',\n",
       "  'redis-cart-57bd646894-9jz9x': '0.0234',\n",
       "  'recommendationservice-599dfdc445-n7b88': '0.1534',\n",
       "  'adservice-6b74979749-5r7p2': '0.0734',\n",
       "  'frontend-597d957cdf-q8x2v': '0.1634'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pod_usage_cpu = {'gke-onlineboutique-default-pool-db17c72b-snh7': {'loadgenerator-88f7dbff5-dwncr':'0.0154'},\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': {'cartservice-6fc79c6d86-q784f': '0.0234',\n",
    "  'shippingservice-5f4d856dc-7rxzk': '0.0434',\n",
    "  'paymentservice-5bdd645d9f-jqmp4': '0.0834',\n",
    "  'checkoutservice-7c95787547-kcqpr': '0.1234'},\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': {'emailservice-799966ff9f-fdscz': '0.0434',\n",
    "  'productcatalogservice-7ffbf4fbf5-rtw8d': '0.0934'},\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': {'currencyservice-67674dbdf7-mx8xc': '0.0634',\n",
    "  'redis-cart-57bd646894-9jz9x': '0.0234',\n",
    "  'recommendationservice-599dfdc445-n7b88': '0.1534',\n",
    "  'adservice-6b74979749-5r7p2': '0.0734',\n",
    "  'frontend-597d957cdf-q8x2v': '0.1634'}}\n",
    "pod_usage_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommendationservice': '364904448.000',\n",
       " 'emailservice': '201326592.000',\n",
       " 'loadgenerator': '402653184.000',\n",
       " 'frontend': '201326592.000',\n",
       " 'productcatalogservice': '201326592.000',\n",
       " 'adservice': '322961408.000',\n",
       " 'paymentservice': '201326592.000',\n",
       " 'shippingservice': '201326592.000',\n",
       " 'currencyservice': '201326592.000',\n",
       " 'cartservice': '201326592.000',\n",
       " 'checkoutservice': '201326592.000',\n",
       " 'redis-cart': '343932928.000'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_request_ram = {'gke-onlineboutique-default-pool-db17c72b-1d5h': '1534066688',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-snh7': '3233808384',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '1103101952',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': '1067450368'}\n",
    "\n",
    "node_request_cpu = {'gke-onlineboutique-default-pool-db17c72b-1d5h': '1.2690000000000001',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-snh7': '1.3330000000000004',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '1.163',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': '1.113'}\n",
    "\n",
    "node_allocated_ram = {'gke-onlineboutique-default-pool-db17c72b-84r9': '6340198400',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '6340198400',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': '6340206592',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-snh7': '6340206592'}\n",
    "\n",
    "max_ram_allocation = 6340206592.0\n",
    "\n",
    "node_allocated_cpu = {'gke-onlineboutique-default-pool-db17c72b-84r9': '1.93',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': '1.93',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': '1.93',\n",
    " 'gke-onlineboutique-default-pool-db17c72b-snh7': '1.93'}\n",
    "max_cpu_allocation = 1.93\n",
    "\n",
    "pod_request_ram = {'recommendationservice-599dfdc445-kd955': '364904448',\n",
    " 'emailservice-799966ff9f-sg5f4': '201326592',\n",
    " 'loadgenerator-88f7dbff5-64rkl': '402653184',\n",
    " 'frontend-597d957cdf-nrw27': '201326592',\n",
    " 'productcatalogservice-7ffbf4fbf5-fcsls': '201326592',\n",
    " 'adservice-6b74979749-4j9p4': '322961408',\n",
    " 'paymentservice-5bdd645d9f-nmdbw': '201326592',\n",
    " 'shippingservice-5f4d856dc-8nxrr': '201326592',\n",
    " 'currencyservice-67674dbdf7-m8rgw': '201326592',\n",
    " 'cartservice-6fc79c6d86-kzng8': '201326592',\n",
    " 'checkoutservice-7c95787547-f4w77': '201326592',\n",
    " 'redis-cart-57bd646894-544n7': '343932928'}\n",
    "\n",
    "pod_request_cpu = {'cartservice-6fc79c6d86-kzng8': '0.30000000000000004',\n",
    " 'checkoutservice-7c95787547-f4w77': '0.2',\n",
    " 'frontend-597d957cdf-nrw27': '0.2',\n",
    " 'currencyservice-67674dbdf7-m8rgw': '0.2',\n",
    " 'redis-cart-57bd646894-544n7': '0.17',\n",
    " 'productcatalogservice-7ffbf4fbf5-fcsls': '0.2',\n",
    " 'adservice-6b74979749-4j9p4': '0.30000000000000004',\n",
    " 'paymentservice-5bdd645d9f-nmdbw': '0.2',\n",
    " 'shippingservice-5f4d856dc-8nxrr': '0.2',\n",
    " 'emailservice-799966ff9f-sg5f4': '0.2',\n",
    " 'loadgenerator-88f7dbff5-64rkl': '0.4',\n",
    " 'recommendationservice-599dfdc445-kd955': '0.2'}\n",
    "\n",
    "modified_request_cpu = modify_pod_requests(pod_request_cpu)\n",
    "modified_request_ram = modify_pod_requests(pod_request_ram)\n",
    "modified_request_ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gke-onlineboutique-default-pool-db17c72b-snh7',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-1d5h',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-dw0s',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-84r9']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pod_usage_ram = {'gke-onlineboutique-default-pool-db17c72b-snh7': {'loadgenerator-88f7dbff5-dwncr': '44708864.0'},\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': {'checkoutservice-7c95787547-kcqpr': '31964160.0',\n",
    "  'cartservice-6fc79c6d86-q784f': '45246464.0',\n",
    "  'shippingservice-5f4d856dc-7rxzk': '28988416.0',\n",
    "  'paymentservice-5bdd645d9f-jqmp4': '42295296.0'},\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': {'emailservice-799966ff9f-fdscz': '44172288.0',\n",
    "  'productcatalogservice-7ffbf4fbf5-rtw8d': '29509632.0'},\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': {'recommendationservice-599dfdc445-n7b88': '45473792.0',\n",
    "  'adservice-6b74979749-5r7p2': '85533696.0',\n",
    "  'frontend-597d957cdf-q8x2v': '32999424.0',\n",
    "  'currencyservice-67674dbdf7-mx8xc': '45135872.0',\n",
    "  'redis-cart-57bd646894-9jz9x': '25831424.0'}}\n",
    "pod_usage_ram\n",
    "\n",
    "host_list = []\n",
    "for host in pod_usage_ram:\n",
    "    host_list.append(host)\n",
    "host_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loadgenerator': '0.015',\n",
       " 'cartservice': '0.023',\n",
       " 'shippingservice': '0.043',\n",
       " 'paymentservice': '0.083',\n",
       " 'checkoutservice': '0.123',\n",
       " 'emailservice': '0.043',\n",
       " 'productcatalogservice': '0.093',\n",
       " 'currencyservice': '0.063',\n",
       " 'redis-cart': '0.023',\n",
       " 'recommendationservice': '0.153',\n",
       " 'adservice': '0.073',\n",
       " 'frontend': '0.163'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_pod_cpu = modify_pod_resources(pod_usage_cpu)\n",
    "modified_pod_ram = modify_pod_resources(pod_usage_ram)\n",
    "modified_pod_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gke-onlineboutique-default-pool-db17c72b-snh7': ['loadgenerator-88f7dbff5-dwncr'],\n",
       " 'gke-onlineboutique-default-pool-db17c72b-1d5h': ['cartservice-6fc79c6d86-q784f',\n",
       "  'shippingservice-5f4d856dc-7rxzk',\n",
       "  'paymentservice-5bdd645d9f-jqmp4',\n",
       "  'checkoutservice-7c95787547-kcqpr'],\n",
       " 'gke-onlineboutique-default-pool-db17c72b-dw0s': ['emailservice-799966ff9f-fdscz',\n",
       "  'productcatalogservice-7ffbf4fbf5-rtw8d'],\n",
       " 'gke-onlineboutique-default-pool-db17c72b-84r9': ['currencyservice-67674dbdf7-mx8xc',\n",
       "  'redis-cart-57bd646894-9jz9x',\n",
       "  'recommendationservice-599dfdc445-n7b88',\n",
       "  'adservice-6b74979749-5r7p2',\n",
       "  'frontend-597d957cdf-q8x2v']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_placement = {'gke-onlineboutique-default-pool-db17c72b-snh7': ['loadgenerator-88f7dbff5-dwncr'],\n",
    " 'gke-onlineboutique-default-pool-db17c72b-1d5h': ['cartservice-6fc79c6d86-q784f',\n",
    "  'shippingservice-5f4d856dc-7rxzk',\n",
    "  'paymentservice-5bdd645d9f-jqmp4',\n",
    "  'checkoutservice-7c95787547-kcqpr'],\n",
    " 'gke-onlineboutique-default-pool-db17c72b-dw0s': ['emailservice-799966ff9f-fdscz',\n",
    "  'productcatalogservice-7ffbf4fbf5-rtw8d'],\n",
    " 'gke-onlineboutique-default-pool-db17c72b-84r9': ['currencyservice-67674dbdf7-mx8xc',\n",
    "  'redis-cart-57bd646894-9jz9x',\n",
    "  'recommendationservice-599dfdc445-n7b88',\n",
    "  'adservice-6b74979749-5r7p2',\n",
    "  'frontend-597d957cdf-q8x2v']}\n",
    "initial_placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loadgenerator': 'gke-onlineboutique-default-pool-db17c72b-snh7',\n",
       " 'cartservice': 'gke-onlineboutique-default-pool-db17c72b-1d5h',\n",
       " 'shippingservice': 'gke-onlineboutique-default-pool-db17c72b-1d5h',\n",
       " 'paymentservice': 'gke-onlineboutique-default-pool-db17c72b-1d5h',\n",
       " 'checkoutservice': 'gke-onlineboutique-default-pool-db17c72b-1d5h',\n",
       " 'emailservice': 'gke-onlineboutique-default-pool-db17c72b-dw0s',\n",
       " 'productcatalogservice': 'gke-onlineboutique-default-pool-db17c72b-dw0s',\n",
       " 'currencyservice': 'gke-onlineboutique-default-pool-db17c72b-84r9',\n",
       " 'redis-cart': 'gke-onlineboutique-default-pool-db17c72b-84r9',\n",
       " 'recommendationservice': 'gke-onlineboutique-default-pool-db17c72b-84r9',\n",
       " 'adservice': 'gke-onlineboutique-default-pool-db17c72b-84r9',\n",
       " 'frontend': 'gke-onlineboutique-default-pool-db17c72b-84r9'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_list = ['adservice', 'cartservice', 'checkoutservice', 'currencyservice', 'emailservice', 'frontend', 'loadgenerator', 'paymentservice', 'productcatalogservice', 'recommendationservice', 'shippingservice', 'redis-cart']\n",
    "\n",
    "service_host = {}\n",
    "for host in pod_usage_cpu:\n",
    "    for service in pod_usage_cpu[host]:\n",
    "    #Pattern: service_name-ID-SubID\n",
    "        split_string = re.split(\"-\", service)\n",
    "        if(len(split_string) == 3):\n",
    "            curr_service = split_string[0]\n",
    "        else:\n",
    "            curr_service = split_string[0] + '-'+ split_string[1]\n",
    "         \n",
    "        service_host[curr_service] = host\n",
    "service_host\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkoutservice': {'cartservice': '0.01',\n",
       "  'shippingservice': '0.01',\n",
       "  'emailservice': '0.007',\n",
       "  'paymentservice': '0.007',\n",
       "  'currencyservice': '0.02',\n",
       "  'productcatalogservice': '0.01'},\n",
       " 'recommendationservice': {'productcatalogservice': '0.13'},\n",
       " 'frontend': {'adservice': '0.11',\n",
       "  'cartservice': '0.17',\n",
       "  'checkoutservice': '0.007',\n",
       "  'recommendationservice': '0.13',\n",
       "  'shippingservice': '0.03',\n",
       "  'currencyservice': '0.48',\n",
       "  'productcatalogservice': '0.81'},\n",
       " 'loadgenerator': {'frontend': '0.18'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_affinities = {'checkoutservice': {'cartservice': '0.01',\n",
    "  'shippingservice': '0.01',\n",
    "  'emailservice': '0.007',\n",
    "  'paymentservice': '0.007',\n",
    "  'currencyservice': '0.02',\n",
    "  'productcatalogservice': '0.01'},\n",
    " 'recommendationservice': {'productcatalogservice': '0.13'},\n",
    " 'frontend': {'adservice': '0.11',\n",
    "  'cartservice': '0.17',\n",
    "  'checkoutservice': '0.007',\n",
    "  'recommendationservice': '0.13',\n",
    "  'shippingservice': '0.03',\n",
    "  'currencyservice': '0.48',\n",
    "  'productcatalogservice': '0.81'},\n",
    " 'loadgenerator': {'frontend': '0.18'}}\n",
    "service_affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frontend->productcatalogservice': 0.81,\n",
       " 'frontend->currencyservice': 0.48,\n",
       " 'loadgenerator->frontend': 0.18,\n",
       " 'frontend->cartservice': 0.17,\n",
       " 'recommendationservice->productcatalogservice': 0.13,\n",
       " 'frontend->recommendationservice': 0.13,\n",
       " 'frontend->adservice': 0.11,\n",
       " 'frontend->shippingservice': 0.03,\n",
       " 'checkoutservice->currencyservice': 0.02,\n",
       " 'checkoutservice->cartservice': 0.01,\n",
       " 'checkoutservice->shippingservice': 0.01,\n",
       " 'checkoutservice->productcatalogservice': 0.01,\n",
       " 'checkoutservice->emailservice': 0.007,\n",
       " 'checkoutservice->paymentservice': 0.007,\n",
       " 'frontend->checkoutservice': 0.007}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assemble all affinities in one matrix\n",
    "total_affinities = {}\n",
    "for source_key in service_affinities:\n",
    "    for destination_key in service_affinities[source_key]:\n",
    "        total_affinities[source_key+\"->\"+destination_key] = float(service_affinities[source_key][destination_key])\n",
    "total_affinities = dict(sorted(total_affinities.items(), key=operator.itemgetter(1),reverse=True))\n",
    "total_affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkoutservice': {'currencyservice': '0.02',\n",
       "  'cartservice': '0.01',\n",
       "  'shippingservice': '0.01',\n",
       "  'productcatalogservice': '0.01',\n",
       "  'emailservice': '0.007',\n",
       "  'paymentservice': '0.007'},\n",
       " 'recommendationservice': {'productcatalogservice': '0.13'},\n",
       " 'frontend': {'productcatalogservice': '0.81',\n",
       "  'currencyservice': '0.48',\n",
       "  'cartservice': '0.17',\n",
       "  'recommendationservice': '0.13',\n",
       "  'adservice': '0.11',\n",
       "  'shippingservice': '0.03',\n",
       "  'checkoutservice': '0.007'},\n",
       " 'loadgenerator': {'frontend': '0.18'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_service_affinities = service_affinities.copy()\n",
    "for key in service_affinities:\n",
    "    sorted_service_affinities[key] = dict(sorted(sorted_service_affinities[key].items(), key=operator.itemgetter(1),reverse=True))\n",
    "sorted_service_affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_service_names(current_placement):\n",
    "    initial_placement = {}\n",
    "    for key in current_placement:\n",
    "        initial_placement[key] = []\n",
    "        for index, services in enumerate(current_placement[key]):\n",
    "            # Pattern: service_name-ID-SubID\n",
    "            split_string = re.split(\"-\", services)\n",
    "            if(len(split_string) == 3):\n",
    "                curr_service = split_string[0]\n",
    "            else:\n",
    "                curr_service = split_string[0] + '-'+ split_string[1]\n",
    "            initial_placement[key].append(curr_service)\n",
    "    return initial_placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_construction(services, affinities):\n",
    "    from collections import defaultdict\n",
    "  \n",
    "    # function for adding edge to graph\n",
    "    graph = defaultdict(list)\n",
    "    def addEdge(graph,u,v):\n",
    "        graph[u].append(v)\n",
    "\n",
    "    # definition of function\n",
    "    def generate_edges(graph):\n",
    "        edges = []\n",
    "\n",
    "        # for each node in graph\n",
    "        for node in graph:\n",
    "            # for each neighbour node of a single node\n",
    "            for neighbour in graph[node]:\n",
    "                # if edge exists then append\n",
    "                edges.append((node, neighbour))\n",
    "        return edges\n",
    "\n",
    "    # declaration of graph as dictionary\n",
    "    for source in affinities:\n",
    "        for dest in affinities[source]:\n",
    "            if(source in services and dest in services):\n",
    "                addEdge(graph,source,dest)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_graph(parts, temp_graph, affinities):\n",
    "    curr_graph = copy.deepcopy(temp_graph)\n",
    "    \n",
    "    # Total Edjes\n",
    "    edje_count = 0\n",
    "    for x in temp_graph:\n",
    "        edje_count += len(temp_graph[x])\n",
    "    edje_count\n",
    "    \n",
    "    while edje_count > (parts - 1): # For Binary Partition we need 2 Vertices and 1 Edje - K partition -> K Vertices and K-1 Edjes(at least)\n",
    "        # Pick random source and destination whose affinity hasnt be processed\n",
    "#         pprint.pprint(affinities)\n",
    "#         pprint.pprint(curr_graph)\n",
    "        random_source = random.choice(list(curr_graph.keys()))\n",
    "        random_dest = random.choice((curr_graph[random_source]))\n",
    "        \n",
    "#         print(\"SOURCE\" + random_source)\n",
    "#         print(\"DEST\" + random_dest)\n",
    "        while float(affinities[random_source][random_dest]) == 0.0:\n",
    "            random_source = random.choice(list(curr_graph.keys()))\n",
    "            random_dest = random.choice((curr_graph[random_source]))\n",
    "              \n",
    "        # Check if Random_Dest is also a source and update all the destination services for random_source\n",
    "        if random_dest in curr_graph:\n",
    "            for dest in curr_graph[random_dest]:\n",
    "\n",
    "                # Check if source contains the specific dest - otherwise add service and affinity\n",
    "                if dest in curr_graph[random_source]:\n",
    "                    affinities[random_source][dest] = format(float(float(affinities[random_source][dest]) + float(affinities[random_dest][dest])), '.4f')\n",
    "                    # Decrease Edjes\n",
    "                    edje_count -= 1\n",
    "                else:\n",
    "                    if dest == random_source:\n",
    "                        if len(curr_graph) != 2 or edje_count != 2:\n",
    "                            edje_count -= 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        # Append Service and Add Affinity\n",
    "                        curr_graph[random_source].append(dest)\n",
    "                        affinities[random_source][dest] = format(float(affinities[random_dest][dest]), '.4f')\n",
    "\n",
    "                # Remove affinity\n",
    "                affinities[random_dest].pop(dest)\n",
    "            curr_graph[random_dest].clear()\n",
    "            \n",
    "        \n",
    "        # Search if random_dest has other affinities with other sources \n",
    "        for key in curr_graph:\n",
    "            if key == random_source:\n",
    "                continue\n",
    "            else:\n",
    "                # Check if dest service is also in sources\n",
    "                if random_dest in curr_graph and key == random_dest:\n",
    "                    continue\n",
    "                else:\n",
    "                    # Dest in other affinity sources\n",
    "                    if random_dest in curr_graph[key]:\n",
    "                        # Random Source not in current source affinities -> add service and finally add affinity\n",
    "                        if random_source in curr_graph[key]:\n",
    "                            affinities[key][random_source] = format((float(affinities[key][random_source]) + float(affinities[key][random_dest])), '.4f')\n",
    "                            # Decrease Edjes\n",
    "                            edje_count -= 1\n",
    "                        else: \n",
    "                            curr_graph[key].append(random_source)\n",
    "                            affinities[key][random_source] = format(float(affinities[key][random_dest]), '.4f')\n",
    "                        affinities[key].pop(random_dest)\n",
    "                        curr_graph[key].remove(random_dest)\n",
    "                        \n",
    "        \n",
    "        # Update Source affinity - Remove Dest Service\n",
    "        if len(curr_graph) != 2 or edje_count != 2:\n",
    "            curr_graph[random_source].remove(random_dest)\n",
    "            affinities[random_source][random_dest] = '0.0' # Empty affinity - Means that source contains dest\n",
    "        \n",
    "        # Remove the Empty Dest if Exists \n",
    "        if random_dest in curr_graph:\n",
    "            # Check if random source contained other sources\n",
    "            if bool(affinities[random_dest]):\n",
    "                for key in affinities[random_dest]:\n",
    "                    if key not in affinities[random_source] and key != random_source:\n",
    "                        affinities[random_source][key] = '0.0'\n",
    "            \n",
    "            # Update Graph\n",
    "            curr_graph.pop(random_dest)\n",
    "            affinities.pop(random_dest)\n",
    "        \n",
    "        # Check for empty source\n",
    "        if not bool(curr_graph[random_source]):\n",
    "            curr_graph.pop(random_source)\n",
    "            \n",
    "        # Decrease Edjes\n",
    "        edje_count -= 1\n",
    "#         print(\"EDJE COUNT: \" + str(edje_count))\n",
    "        \n",
    "    # Update the partition\n",
    "    app_partition = {}\n",
    "    # Check for empty affinities\n",
    "    if len(curr_graph) != len(affinities):\n",
    "        host_service = ''\n",
    "        empty_host = ''\n",
    "        for key in affinities:\n",
    "            if key not in curr_graph:\n",
    "                empty_host = key\n",
    "            else:\n",
    "                host_service = key\n",
    "        \n",
    "        # Check the empty host services\n",
    "        for key in affinities[empty_host]:\n",
    "            if key not in affinities[host_service]:\n",
    "                affinities[host_service][key] = '0.0'\n",
    "        if empty_host not in affinities[host_service]:\n",
    "            affinities[host_service][empty_host] = '0.0'\n",
    "        affinities.pop(empty_host)\n",
    "            \n",
    "    curr_graph = copy.deepcopy(affinities)\n",
    "    for source in curr_graph:\n",
    "        app_partition[source] = []\n",
    "        for dest in curr_graph[source]:\n",
    "            if curr_graph[source][dest] != '0.0':\n",
    "                app_partition[dest] = []\n",
    "            else:\n",
    "                app_partition[source].append(dest) \n",
    "        \n",
    "    return app_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_node_available_cpu = {}\n",
    "current_node_available_ram = {}\n",
    "\n",
    "\n",
    "alpha = 1.0 # Initial amount of resources used\n",
    "delta = 0.1 # Function Step\n",
    "\n",
    "# print(\"---------------------------------------\")\n",
    "# pprint.pprint(current_placement)\n",
    "# pprint.pprint(current_node_available_cpu)\n",
    "# pprint.pprint(current_node_available_ram)\n",
    "# print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_packing(app_partition, current_placement, host_service_update, current_node_available_cpu, current_node_available_ram, current_node_usage_cpu, current_node_usage_ram):\n",
    "    final_placement = {}\n",
    "    # Iterate through all parts\n",
    "    for part in app_partition:\n",
    "        max_tf = 0.0\n",
    "        max_ml_ram = 0.0\n",
    "        max_ml_cpu = 0.0\n",
    "        max_host = ''\n",
    "        total_ram = 0.0\n",
    "        total_cpu = 0.0\n",
    "        \n",
    "         # Calculate Resource Demands\n",
    "        for service in app_partition[part]:\n",
    "                \n",
    "            # Calculate resources for current service\n",
    "            temp_cpu = float(modified_request_cpu[service])\n",
    "            temp_ram = float(modified_request_ram[service])\n",
    "\n",
    "            total_cpu += temp_cpu\n",
    "            total_ram += temp_ram\n",
    "            \n",
    "        # Iterate through available hosts\n",
    "        for host in host_list:\n",
    "            enough_resources = False\n",
    "            \n",
    "            if(total_cpu < float(current_node_available_cpu[host]) and total_ram < float(current_node_available_ram[host])):\n",
    "                enough_resources = True\n",
    "                \n",
    "            # Check if resource demands are enough\n",
    "            if(enough_resources):\n",
    "                temp_tf = 0.0\n",
    "                temp_ml_cpu = 0.0\n",
    "                temp_ml_ram = 0.0\n",
    "                    \n",
    "                # Calculate Traffic rates between services in current part of partition and services in current host\n",
    "                for service in app_partition[part]:\n",
    "                    for x in current_placement[host]:\n",
    "                        if service in current_placement[host] and x in current_placement[host]:\n",
    "                            continue # Same host\n",
    "                        else: # Different hosts\n",
    "                            if(service in service_affinities):\n",
    "                                if(x in service_affinities[service]):\n",
    "                                    temp_tf += float(service_affinities[service][x])\n",
    "                            elif(x in service_affinities):\n",
    "                                if(service in service_affinities[x]):\n",
    "                                    temp_tf += float(service_affinities[x][service])\n",
    "                    \n",
    "                # Calculate Most Loaded Situation - Prioritize CPU\n",
    "                temp_ml_cpu = float(current_node_usage_cpu[host]) + total_cpu\n",
    "                temp_ml_ram = float(current_node_usage_ram[host]) + total_ram\n",
    "                    \n",
    "                # Check Traffic Rates and Most-Loaded Situtations - Maximum searched\n",
    "                if (temp_tf > max_tf) or (temp_tf == max_tf and temp_ml_cpu > max_ml_cpu) or (temp_tf == max_tf and temp_ml_cpu == max_ml_cpu and temp_ml_ram > max_ml_ram):\n",
    "                    max_tf = temp_tf\n",
    "                    max_ml_cpu = temp_ml_cpu\n",
    "                    max_ml_ram = temp_ml_ram\n",
    "                    max_host = host\n",
    "       \n",
    "        # Check max_host\n",
    "        if max_host == '':\n",
    "            return {}\n",
    "        else:\n",
    "            current_node_available_cpu[max_host] = float(current_node_available_cpu[max_host]) - total_cpu\n",
    "            current_node_available_ram[max_host] = float(current_node_available_ram[max_host]) - total_ram\n",
    "            current_node_usage_cpu[max_host] = float(current_node_usage_cpu[max_host]) + total_cpu\n",
    "            current_node_usage_ram[max_host] = float(current_node_usage_ram[max_host]) + total_ram\n",
    "            \n",
    "            # Update placement\n",
    "            if max_host not in final_placement:\n",
    "                final_placement[max_host] = []\n",
    "                \n",
    "            for service in app_partition[part]:\n",
    "                host_service_update[service] = max_host    \n",
    "                final_placement[max_host].append(service)\n",
    "                             \n",
    "    return final_placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_placement(placement_solution, partition_services, hosts_packed, host_service_update, current_node_available_cpu,current_node_available_ram):\n",
    "\n",
    "    for host in placement_solution:\n",
    "        if host in hosts_packed:\n",
    "            continue\n",
    "            \n",
    "        for service in placement_solution[host]:\n",
    "            if service in partition_services:\n",
    "                continue\n",
    "            else:\n",
    "                # Check the affinity of service\n",
    "                if service in sorted_service_affinities:\n",
    "                    # Find max dest and check if there are enough resources\n",
    "                    for dest in sorted_service_affinities[service]:\n",
    "                        temp_host_dest = host_service_update[dest]\n",
    "                        \n",
    "                        # Check if they are on same host\n",
    "                        if temp_host_dest == host:\n",
    "                            continue\n",
    "                            \n",
    "                        # Check if there are enough resources\n",
    "                        if current_node_available_cpu[temp_host_dest] > modified_request_cpu[service] and current_node_available_ram[temp_host_dest] > modified_request_ram[service]:\n",
    "                            # CPU resources update\n",
    "                            current_node_available_cpu[temp_host_dest] = float(current_node_available_cpu[temp_host_dest]) - float(modified_request_cpu[service])\n",
    "                            current_node_available_cpu[host] = float(current_node_available_cpu[host]) + float(modified_request_ram[service])\n",
    "\n",
    "                            # RAM resources update\n",
    "                            current_node_available_ram[temp_host_dest] = float(current_node_available_ram[temp_host_dest]) - float(modified_request_ram[service])\n",
    "                            current_node_available_ram[host] = float(current_node_available_ram[host]) + float(modified_request_cpu[service])\n",
    "\n",
    "                            # Host services transfer and update\n",
    "                            placement_solution[host].remove(service)\n",
    "                            placement_solution[temp_host_dest].append(service)\n",
    "                            partition_services.append(service)\n",
    "                else:\n",
    "                    for source in sorted_service_affinities:\n",
    "                        for dest in sorted_service_affinities[source]:\n",
    "                            if dest == service:\n",
    "                                temp_host_source = host_service_update[source]\n",
    "\n",
    "                                # Check if they are on same host\n",
    "                                if temp_host_source == host:\n",
    "                                    continue\n",
    "\n",
    "                                # Check if there are enough resources\n",
    "                                if current_node_available_cpu[temp_host_source] > modified_request_cpu[service] and current_node_available_ram[temp_host_source] > modified_request_ram[service]:\n",
    "                                    # CPU resources update\n",
    "                                    current_node_available_cpu[temp_host_source] = float(current_node_available_cpu[temp_host_source]) - float(modified_request_cpu[service])\n",
    "                                    current_node_available_cpu[host] = float(current_node_available_cpu[host]) + float(modified_request_cpu[service])\n",
    "\n",
    "                                    # RAM resources update\n",
    "                                    current_node_available_ram[temp_host_source] = float(current_node_available_ram[temp_host_source]) - float(modified_request_ram[service])\n",
    "                                    current_node_available_ram[host] = float(current_node_available_ram[host]) + float(modified_request_ram[service])\n",
    "                                    # Host services transfer and update\n",
    "                                    placement_solution[host].remove(service)\n",
    "                                    placement_solution[temp_host_source].append(service)\n",
    "                                    partition_services.append(service)\n",
    "                                    break\n",
    "                        \n",
    "                        if service in partition_services:\n",
    "                            break\n",
    "    return placement_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_available_node_resources(node_requests, node_max_values):\n",
    "    available_resources = {}\n",
    "    for host in node_requests:\n",
    "        available_resources[host] = float(node_max_values[host])- float(node_requests[host])\n",
    "    return available_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_node_resources(host_per_service, current_node_available_cpu, current_node_available_ram, current_node_usage_cpu, current_node_usage_ram):\n",
    "    for service in host_per_service:\n",
    "        curr_host = host_per_service[service]\n",
    "        current_node_available_cpu[curr_host] = float(current_node_available_cpu[curr_host]) + float(modified_request_cpu[service])\n",
    "        current_node_available_ram[curr_host] = float(current_node_available_ram[curr_host]) + float(modified_request_ram[service])\n",
    "        current_node_usage_cpu[curr_host] = float(current_node_usage_cpu[curr_host]) - float(modified_request_cpu[service])\n",
    "        current_node_usage_ram[curr_host] = float(current_node_usage_ram[curr_host]) - float(modified_request_cpu[service])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': ['adservice'],\n",
      " '3': ['paymentservice'],\n",
      " '5': ['emailservice'],\n",
      " '7': ['shippingservice'],\n",
      " '8': ['cartservice',\n",
      "       'currencyservice',\n",
      "       'productcatalogservice',\n",
      "       'checkoutservice'],\n",
      " '9': ['frontend', 'recommendationservice', 'checkoutservice', 'loadgenerator']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gke-onlineboutique-default-pool-db17c72b-snh7': ['paymentservice'],\n",
       " 'gke-onlineboutique-default-pool-db17c72b-1d5h': ['emailservice'],\n",
       " 'gke-onlineboutique-default-pool-db17c72b-84r9': ['shippingservice',\n",
       "  'cartservice',\n",
       "  'currencyservice',\n",
       "  'productcatalogservice',\n",
       "  'checkoutservice'],\n",
       " 'gke-onlineboutique-default-pool-db17c72b-dw0s': ['frontend',\n",
       "  'recommendationservice',\n",
       "  'loadgenerator',\n",
       "  'adservice',\n",
       "  'redis-cart']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while alpha >= 0.0:   \n",
    "    # Gather Resources\n",
    "    current_node_available_cpu = calculate_available_node_resources(node_request_cpu,node_allocated_cpu)\n",
    "    current_node_available_ram = calculate_available_node_resources(node_request_ram,node_allocated_ram)\n",
    "    current_placement = copy.deepcopy(initial_placement)\n",
    "    \n",
    "    # Adjusting the placement dictionary\n",
    "    current_placement = adjust_service_names(current_placement)\n",
    "    \n",
    "    current_node_usage_cpu = copy.deepcopy(node_request_cpu)\n",
    "    current_node_usage_ram = copy.deepcopy(node_request_ram)\n",
    "    \n",
    "    \n",
    "    # Partition Application\n",
    "    app_partition = {}\n",
    "    curr_partition = {}\n",
    "    curr_partition['1'] = service_list.copy()\n",
    "    total_parts = len(curr_partition)\n",
    "    k_partition = 2\n",
    "    \n",
    "    # Iterate until we find a suitable partition\n",
    "    while(True):\n",
    "        app_partition = copy.deepcopy(curr_partition)\n",
    "        # Gather Resource demands and Number of Services\n",
    "        for part in app_partition:\n",
    "            sum_cpu_usage = 0.0\n",
    "            sum_ram_usage = 0.0\n",
    "            check_resource_demands = True\n",
    "            check_number_of_services = True\n",
    "\n",
    "            # Check if part contains more than one service\n",
    "            if(len(app_partition[part]) <= 1):\n",
    "                check_number_of_services = False\n",
    "\n",
    "            # Check resource demands and if they exceed alpha \n",
    "            for service in app_partition[part]:\n",
    "                temp_cpu = float(modified_request_cpu[service])\n",
    "                temp_ram = float(modified_request_ram[service])\n",
    "\n",
    "                sum_cpu_usage += temp_cpu\n",
    "                sum_ram_usage += temp_ram\n",
    "            \n",
    "            if(sum_cpu_usage < (max_cpu_allocation * alpha) and \n",
    "               sum_ram_usage < (max_ram_allocation * alpha)):\n",
    "                check_resource_demands = False\n",
    "            \n",
    "            # Cannot meet Criteria - Partition Application Part\n",
    "            if(check_number_of_services and check_resource_demands):\n",
    "                contraction_repeats = len(app_partition[part])\n",
    "                temp_graph = graph_construction(app_partition[part], service_affinities)\n",
    "                min_graph = copy.deepcopy(temp_graph)\n",
    "                partitioned_graph = {}\n",
    "                min_sum = 0.0\n",
    "                temp_sum = 0.0\n",
    "                min_tf={}\n",
    "                \n",
    "                # Find part service affinities and min sum\n",
    "                part_service_traffic = {}\n",
    "                for source in temp_graph:\n",
    "                    part_service_traffic[source] = {}\n",
    "                    for dest in temp_graph[source]:\n",
    "                        part_service_traffic[source][dest] = float(service_affinities[source][dest])\n",
    "                        min_sum += float(service_affinities[source][dest])\n",
    "                \n",
    "                # Remove current part\n",
    "                curr_partition.pop(part)\n",
    "                \n",
    "                # Contraction Algorithm\n",
    "                while(contraction_repeats > 0):\n",
    "                    # Apply contraction Algorithm\n",
    "                    service_traffic = copy.deepcopy(part_service_traffic)\n",
    "                    partitioned_graph = contract_graph(k_partition, temp_graph, service_traffic)\n",
    "                    \n",
    "                    # Compare with minimum - Check if null\n",
    "                    if(bool(partitioned_graph)):\n",
    "                        for service in service_traffic:\n",
    "                            for x in service_traffic[service]:\n",
    "                                    temp_sum += float(service_traffic[service][x])\n",
    "                        \n",
    "                       \n",
    "                        # Check if another minimum Graph found\n",
    "                        if temp_sum < min_sum:\n",
    "                            min_graph = partitioned_graph\n",
    "                            min_sum = temp_sum\n",
    "                            min_tf = service_traffic\n",
    "                            \n",
    "                    # Decrease repeats\n",
    "                    temp_sum = 0.0\n",
    "                    contraction_repeats -= 1\n",
    "                    \n",
    "                # Partition the application and repeat process\n",
    "                for key in min_graph:\n",
    "                    curr_partition[str(total_parts+1)] = min_graph[key]\n",
    "                    curr_partition[str(total_parts+1)].append(key)\n",
    "                    total_parts += 1\n",
    "                \n",
    "        # Identical dictionaries - No changes happen - Break\n",
    "        if app_partition == curr_partition:\n",
    "            break\n",
    "    \n",
    "    pprint.pprint(app_partition)\n",
    "    partition_services = []\n",
    "    duplicate_parts = []\n",
    "    duplicate_service = []\n",
    "    for part in app_partition:\n",
    "        for service in app_partition[part]:\n",
    "            # Find duplicate services\n",
    "            if service in partition_services:\n",
    "                duplicate_service.append(service)\n",
    "                duplicate_parts.append(part)\n",
    "                continue\n",
    "            partition_services.append(service)\n",
    "    \n",
    "    # Fix duplicate services\n",
    "    part_counter = 0\n",
    "    for x in duplicate_parts:\n",
    "        app_partition[x].remove(duplicate_service[part_counter])\n",
    "        part_counter += 1\n",
    "        if not bool(app_partition[x]):\n",
    "            app_partition.pop(x)\n",
    "            \n",
    "    placement_solution = {}\n",
    "    host_service_update = copy.deepcopy(service_host)\n",
    "    # Function to calculate the true available resources without the current services of app\n",
    "    update_node_resources(host_service_update, current_node_available_cpu, current_node_available_ram, current_node_usage_cpu, current_node_usage_ram)\n",
    "    pprint.pprint(app_partition)\n",
    "    # Apply Heuristic Packing\n",
    "    placement_solution = heuristic_packing(app_partition, current_placement,\n",
    "                                            host_service_update, current_node_available_cpu, \n",
    "                                           current_node_available_ram, current_node_usage_cpu, \n",
    "                                           current_node_usage_ram)\n",
    "    \n",
    "    # Check if a placement solution was found\n",
    "    if bool(placement_solution): \n",
    "        # Find hosts changed during packing \n",
    "        hosts_packed = []\n",
    "        for service in host_service_update:\n",
    "            if service in partition_services:\n",
    "                if host_service_update[service] in hosts_packed:\n",
    "                    continue\n",
    "                else:\n",
    "                    hosts_packed.append(host_service_update[service])\n",
    "                    \n",
    "        # Add services with unused traffic (According to Most - Loaded situation)\n",
    "        successful_placement = True\n",
    "        for service in host_service_update:\n",
    "            host_found = False\n",
    "            if service in partition_services:\n",
    "                host_found = True\n",
    "                continue # Service Partitioned\n",
    "            else:\n",
    "                # Unpartitioned service - No traffic - Place it to most-loaded host\n",
    "                max_host = ''\n",
    "                for host in hosts_packed:\n",
    "                    # Check if service can be packed to this host\n",
    "                    if(float(modified_pod_cpu[service]) < float(current_node_available_cpu[host]) and float(modified_pod_ram[service]) < float(current_node_available_ram[host])):\n",
    "                        if(max_host != ''):\n",
    "                            if(float(current_node_available_cpu[host]) < float(current_node_available_cpu[max_host])):\n",
    "                                max_host = host\n",
    "                        else:\n",
    "                            max_host = host\n",
    "                \n",
    "               \n",
    "                if max_host != '':\n",
    "                    placement_solution[max_host].append(service)\n",
    "                    current_node_available_cpu[max_host] = float(current_node_available_cpu[max_host]) - float(modified_pod_cpu[service])\n",
    "                    current_node_available_ram[max_host] = float(current_node_available_ram[max_host]) - float(modified_pod_ram[service])\n",
    "                    current_node_usage_cpu[max_host] = float(current_node_usage_cpu[max_host]) + float(modified_pod_cpu[service])\n",
    "                    current_node_usage_ram[max_host] = float(current_node_usage_ram[max_host]) + float(modified_pod_ram[service])\n",
    "                    host_found = True\n",
    "                else:        \n",
    "                    # No Host found so check the remaining hosts of initial placement\n",
    "                    for host in host_list:\n",
    "                        if host in hosts_packed:\n",
    "                            continue # Host already Checked\n",
    "                        else:\n",
    "                             if(float(modified_pod_cpu[service]) < float(current_node_available_cpu[host]) and float(modified_pod_ram[service]) < float(current_node_available_cpu[host])):\n",
    "                                placement_solution[host].append(service)\n",
    "                                current_node_available_cpu[max_host] = float(current_node_available_cpu[max_host]) - float(modified_pod_cpu[service])\n",
    "                                current_node_available_ram[max_host] = float(current_node_available_ram[max_host]) - float(modified_pod_ram[service])\n",
    "                                current_node_usage_cpu[max_host] = float(current_node_usage_cpu[max_host]) + float(modified_pod_cpu[service])\n",
    "                                current_node_usage_ram[max_host] = float(current_node_usage_ram[max_host]) + float(modified_pod_ram[service])\n",
    "                                host_found = True\n",
    "                                break\n",
    "                \n",
    "                if host_found:\n",
    "                    continue\n",
    "                else:\n",
    "                    # No Host available found - Proceed to next alpha value\n",
    "                    successful_placement = False\n",
    "                    break\n",
    "        \n",
    "        if(successful_placement):\n",
    "            break # Placement Found - Exit\n",
    "        else:\n",
    "            continue # Proceed to next alpha\n",
    "                    \n",
    "    alpha -= delta\n",
    "placement_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
