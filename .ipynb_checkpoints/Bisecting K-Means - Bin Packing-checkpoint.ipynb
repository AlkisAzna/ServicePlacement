{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing Service Placement for MicroserviceArchitecture in Clouds - Paper\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pprint\n",
    "import operator\n",
    "import random\n",
    "import copy\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_affinities = {'checkoutservice': {'cartservice': '0.01',\n",
    "  'shippingservice': '0.01',\n",
    "  'emailservice': '0.007',\n",
    "  'paymentservice': '0.007',\n",
    "  'currencyservice': '0.02',\n",
    "  'productcatalogservice': '0.01'},\n",
    " 'recommendationservice': {'productcatalogservice': '0.13'},\n",
    " 'frontend': {'adservice': '0.11',\n",
    "  'cartservice': '0.17',\n",
    "  'checkoutservice': '0.007',\n",
    "  'recommendationservice': '0.13',\n",
    "  'shippingservice': '0.03',\n",
    "  'currencyservice': '0.48',\n",
    "  'productcatalogservice': '0.81'},\n",
    " 'loadgenerator': {'frontend': '0.18'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Info of Placement\n",
    "vm_external_ip = \"34.141.63.138\" #External ip for host machine to fetch the data\n",
    "kiali_port = 32002\n",
    "prometheus_port = 32003\n",
    "\n",
    "namespace = \"default\" # the namespace of the app \n",
    "\n",
    "cluster_id = \"onlineboutique\" # Cluster name\n",
    "\n",
    "cluster_pool = \"default-pool\" # Node pool\n",
    "\n",
    "project_id = \"single-verve-297917\" # Project-ID\n",
    "\n",
    "zone = \"europe-west3-b\" # Project-zone\n",
    "\n",
    "vm_threshold_per_pod = 0.1 # Threshold for reserving sufficient resources for each pod\n",
    "\n",
    "# Connect to cluster command\n",
    "connection_command = \"gcloud container clusters get-credentials onlineboutique --zone europe-west3-b --project single-verve-297917\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information metrics from prometheus about current nodes and pods\n",
    "\n",
    "# Url from prometheus\n",
    "url_prometheus = \"http://\"+vm_external_ip+\":\"+str(prometheus_port)+\"/api/v1/query\"\n",
    "\n",
    "# RAM USAGE PERCENT\n",
    "# (1 - (node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)))* 100\n",
    "# # CPU USAGE PERCENT\n",
    "# (1 - avg(rate(node_cpu_seconds_total{mode=\"idle\"}[30m])) by (instance)) * 100\n",
    "\n",
    "# #PODS CPU USAGE PERCENT (EXCEPT NODE-EXPORTERS)\n",
    "# avg(rate(container_cpu_usage_seconds_total{pod!~\"billowing.*\", namespace='default'}[30m])) by (pod) *100\n",
    "\n",
    "# #PODS MEMORY USAGE (EXCEPT NODE-EXPORTERS)\n",
    "# avg(container_memory_max_usage_bytes{namespace=\"default\", pod!~\"billowing.*\"}) by(pod)\n",
    "\n",
    "# Queries for useful information of Prometheus\n",
    "query_node_cpu = {\"query\":\"avg(rate(node_cpu_seconds_total{mode='idle'}[30m])) by (instance)\"}\n",
    "query_node_ram = {\"query\":\"node_memory_MemAvailable_bytes\"}\n",
    "\n",
    "# Headers of cURL command\n",
    "headers_prometheus = {\n",
    "    'cache-control': \"no-cache\"\n",
    "}\n",
    "\n",
    "# cURL command for Node Ram Usage\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=query_node_ram)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "number_of_hosts = len(result[\"data\"][\"result\"])\n",
    "host_machines = []\n",
    "node_available_ram = {}\n",
    "\n",
    "for i in range(number_of_hosts):\n",
    "    host_machines.append(result[\"data\"][\"result\"][i][\"metric\"][\"kubernetes_node\"])\n",
    "    node_available_ram[host_machines[i]] = format(float(result[\"data\"][\"result\"][i][\"value\"][1]), '.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cURL command for Node Available CPU\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=query_node_cpu)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "node_available_cpu = {}\n",
    "for i in range(number_of_hosts):\n",
    "     node_available_cpu[host_machines[i]] = format(float(result[\"data\"][\"result\"][i][\"value\"][1]), '.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_request = {\"query\":\"sum(kube_pod_container_resource_requests_cpu_cores) by (node)\"}\n",
    "\n",
    "# cURL command for Node Ram Usage\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=app_request)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "node_request_cpu = {}\n",
    "for x in result['data']['result']:\n",
    "    node_request_cpu[x['metric']['node']] = x['value'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_request = {\"query\":\"sum(kube_pod_container_resource_requests_memory_bytes) by (node)\"}\n",
    "\n",
    "# cURL command for Node Ram Usage\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=app_request)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "node_request_ram = {}\n",
    "for x in result['data']['result']:\n",
    "    node_request_ram[x['metric']['node']] = x['value'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_request = {\"query\":\"sum(kube_pod_container_resource_requests_memory_bytes{namespace='default'}) by (pod)\"}\n",
    "\n",
    "# cURL command for Node Ram Usage\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=app_request)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "pod_request_ram = {}\n",
    "for x in result['data']['result']:\n",
    "    pod_request_ram[x['metric']['pod']] = x['value'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_request = {\"query\":\"sum(kube_pod_container_resource_requests_cpu_cores{namespace='default'}) by (pod)\"}\n",
    "\n",
    "# cURL command for Node Ram Usage\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=app_request)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "pod_request_cpu = {}\n",
    "for x in result['data']['result']:\n",
    "    pod_request_cpu[x['metric']['pod']] = x['value'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_request = {\"query\":\"kube_node_status_allocatable{resource='memory'}\"}\n",
    "\n",
    "# cURL command for Node Ram Usage\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=app_request)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "node_allocated_ram = {}\n",
    "for x in result['data']['result']:\n",
    "    node_allocated_ram[x['metric']['node']] = x['value'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_request = {\"query\":\"kube_node_status_allocatable{resource='cpu'}\"}\n",
    "\n",
    "# cURL command for Node Ram Usage\n",
    "response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=app_request)\n",
    "response_status = response.status_code\n",
    "result=json.loads(response.text)\n",
    "\n",
    "node_allocated_cpu = {}\n",
    "for x in result['data']['result']:\n",
    "    node_allocated_cpu[x['metric']['node']] = x['value'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gke-onlineboutique-default-pool-db17c72b-bmch',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-s8x5',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-wtz1',\n",
       " 'gke-onlineboutique-default-pool-db17c72b-zsvj']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_list = []\n",
    "for host in node_allocated_cpu:\n",
    "    host_list.append(host)\n",
    "host_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD CPU USAGE\n",
    "deployment_pods = []\n",
    "pod_usage_cpu = {}\n",
    "initial_placement = {}\n",
    "for i in range(number_of_hosts):\n",
    "    query_pod_cpu = {\"query\":\"avg(rate(container_cpu_usage_seconds_total{kubernetes_io_hostname='\"+str(host_machines[i])+\"',pod!~'billowing.*', namespace='default'}[30m])) by (pod)\"}\n",
    "    pod_usage_cpu[host_machines[i]] = {}\n",
    "    \n",
    "    # cURL command for Pod Cpu Usage\n",
    "    response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=query_pod_cpu)\n",
    "    response_status = response.status_code\n",
    "    result=json.loads(response.text)\n",
    "    \n",
    "    initial_placement[host_machines[i]] = []\n",
    "    service_list = []\n",
    "    number_of_pods = len(result[\"data\"][\"result\"])\n",
    "    for k in range(number_of_pods):\n",
    "         service_list.append(result[\"data\"][\"result\"][k][\"metric\"][\"pod\"])\n",
    "         initial_placement[host_machines[i]].append(service_list[k])\n",
    "         pod_usage_cpu[host_machines[i]][service_list[k]] = format(float(result[\"data\"][\"result\"][k][\"value\"][1]), '.4f')\n",
    "    deployment_pods.append(service_list)\n",
    "    service_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD RAM USAGE\n",
    "pod_usage_ram = {}\n",
    "\n",
    "for i in range(number_of_hosts):\n",
    "    query_pod_ram = {\"query\":\"avg(container_memory_max_usage_bytes{instance='\"+host_machines[i]+\"', namespace='default', pod!~'billowing.*'}) by(pod)\"}\n",
    "    pod_usage_ram[host_machines[i]] = {}\n",
    "    \n",
    "    # cURL command for Pod Ram Usage\n",
    "    response = requests.request(\"GET\", url_prometheus, headers=headers_prometheus, params=query_pod_ram)\n",
    "    response_status = response.status_code\n",
    "    result=json.loads(response.text)\n",
    "    \n",
    "    number_of_pods = len(result[\"data\"][\"result\"])\n",
    "    for k in range(number_of_pods):\n",
    "         pod = result[\"data\"][\"result\"][k][\"metric\"][\"pod\"]\n",
    "         pod_usage_ram[host_machines[i]][pod] = format(float(result[\"data\"][\"result\"][k][\"value\"][1]), '.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph Integration from Kiali - Services and Affinities\n",
    "\n",
    "# Url of Kiali Graph\n",
    "url_kiali = \"http://\"+vm_external_ip+\":\"+str(kiali_port)+\"/kiali/api/namespaces/graph\"\n",
    "\n",
    "query_string_kiali = {\"duration\":\"30m\",\"namespaces\":namespace,\"graphType\":\"workload\"} # Graph type must be Wokload and i can change the graph duration\n",
    "\n",
    "headers_kiali = {\n",
    "    'cache-control': \"no-cache\"\n",
    "}\n",
    "\n",
    "# cURL command\n",
    "response = requests.request(\"GET\", url_kiali, headers=headers_kiali, params=query_string_kiali)\n",
    "\n",
    "response_status = response.status_code\n",
    "\n",
    "result=json.loads(response.text)\n",
    "# INFO NOTE: redis-cart won't appear from kiali graph. There must be internal communication between car\n",
    "#            cartservice and redis-cart so these two pods should be together and calculate as one\n",
    "# Graph Services ID\n",
    "services_id = {}\n",
    "unused_services_id = {}\n",
    "for i in range(len(result[\"elements\"][\"nodes\"])):\n",
    "    if(result[\"elements\"][\"nodes\"][i][\"data\"][\"namespace\"] == namespace):\n",
    "        if(\"app\" not in result[\"elements\"][\"nodes\"][i][\"data\"] or \"traffic\" not in result[\"elements\"][\"nodes\"][i][\"data\"]):\n",
    "            if(\"app\" in result[\"elements\"][\"nodes\"][i][\"data\"]):\n",
    "                key = result[\"elements\"][\"nodes\"][i][\"data\"][\"id\"]\n",
    "                unused_services_id[key] = result[\"elements\"][\"nodes\"][i][\"data\"][\"app\"]\n",
    "                continue\n",
    "            key = result[\"elements\"][\"nodes\"][i][\"data\"][\"id\"]\n",
    "            unused_services_id[key] = result[\"elements\"][\"nodes\"][i][\"data\"][\"service\"]\n",
    "            continue\n",
    "        key = result[\"elements\"][\"nodes\"][i][\"data\"][\"id\"]\n",
    "        services_id[key] = result[\"elements\"][\"nodes\"][i][\"data\"][\"app\"]\n",
    "\n",
    "# Graph edges - Affinities\n",
    "service_affinities = {}\n",
    "service_response_times = {}\n",
    "service_list = []\n",
    "for key in services_id:\n",
    "    service_list.append(services_id[key])\n",
    "service_list.append('redis-cart')\n",
    "\n",
    "total_edjes =len(result[\"elements\"][\"edges\"]) \n",
    "for i in range(total_edjes):\n",
    "    source_id=result[\"elements\"][\"edges\"][i][\"data\"][\"source\"] # Source ID\n",
    "    destination_id=result[\"elements\"][\"edges\"][i][\"data\"][\"target\"] # Destination ID\n",
    "    # Avoid traces from unused services dictionary\n",
    "    if((source_id in unused_services_id.keys()) or (destination_id in unused_services_id.keys())):\n",
    "        continue\n",
    "    \n",
    "    # Track all traces in service id\n",
    "    if((source_id in services_id.keys()) and (destination_id in services_id.keys())):\n",
    "        if(services_id[source_id] not in service_affinities.keys()):\n",
    "            service_affinities[services_id[source_id]] = {}\n",
    "            service_response_times[services_id[source_id]] ={}\n",
    "        if(result[\"elements\"][\"edges\"][i][\"data\"][\"traffic\"][\"protocol\"] == \"http\"):\n",
    "            protocol = \"http\"\n",
    "        else:\n",
    "            protocol = \"grpc\"\n",
    "        service_affinities[services_id[source_id]][services_id[destination_id]] = result[\"elements\"][\"edges\"][i][\"data\"][\"traffic\"][\"rates\"][protocol]\n",
    "        service_response_times[services_id[source_id]][services_id[destination_id]] = result[\"elements\"][\"edges\"][i][\"data\"][\"responseTime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-bcdb1c0ef26a>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-bcdb1c0ef26a>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    first_centroid = first_service\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Bistecting K-Means Algorithm (Input: Service_List, Service_Affinities)\n",
    "def bisecting_k_means(service_list, service_affinities):\n",
    "    # Insert K-Value\n",
    "    while(True):\n",
    "        K_value = input('Choose value for K clusters to be created:')\n",
    "        if K_value.isnumeric():\n",
    "            if int(K_value) <= len(service_list):\n",
    "                break\n",
    "        else:\n",
    "            print(\"Wrong Input! Given input is not an integer Value or greater than service list size!\")\n",
    "\n",
    "    parent_cluster = copy.deepcopy(service_list)\n",
    "    app_clusters = {\"1\": parent_cluster}\n",
    "    cluster_affinities = {\"1\": 0.0}\n",
    "    cluster_count = 1\n",
    "    index = -1\n",
    "    last_index = 1\n",
    "\n",
    "    while(cluster_count < int(K_value)):\n",
    "        # Find the cluster with the least sum of affinities - Maximum Error\n",
    "        min_total_affinity = 100000.0\n",
    "        for x in app_clusters:\n",
    "            # If cluster contains only one service skip\n",
    "            if len(app_clusters[x]) == 1:\n",
    "                continue\n",
    "            if cluster_affinities[x] < min_total_affinity:\n",
    "                parent_cluster = app_clusters[x]\n",
    "                index = x\n",
    "\n",
    "        # Remove the cluster to be split up\n",
    "        app_clusters.pop(index)\n",
    "        cluster_affinities.pop(index)\n",
    "\n",
    "        # Pick centroids according to less or no affinities and remove them from list\n",
    "        if len(parent_cluster) == 2:\n",
    "            # Cluster contains only 2 services - > Make them centroids\n",
    "            first_centroid = random.choice(parent_cluster)\n",
    "            parent_cluster.remove(first_centroid)\n",
    "            second_centroid = random.choice(parent_cluster)\n",
    "            parent_cluster.remove(second_centroid)\n",
    "        else:\n",
    "            centroids_found = False\n",
    "            min_affinity = 1000000000.0\n",
    "            first_centroid = \"\"\n",
    "            second_centroid = \"\"\n",
    "            # Cluster contains more than 2 clusters -> Find min or no affinity and pick the centroids accordingly\n",
    "            for first_service in parent_cluster:\n",
    "                for second_service in parent_cluster:\n",
    "                    if first_service == second_service:\n",
    "                        # Same service\n",
    "                        continue\n",
    "                    else:\n",
    "                        # Check for affinity\n",
    "                        if first_service in service_affinities:\n",
    "                            if second_service in service_affinities[first_service]:\n",
    "                                if min_affinity > float(service_affinities[first_service][second_service]):\n",
    "                                    min_affinity = float(service_affinities[first_service][second_service])\n",
    "                                    first_centroid = first_service\n",
    "                                    second_centroid = second_service\n",
    "                            else:\n",
    "                                # They dont have an affinity so pick them for centroids\n",
    "                                centroids_found = True\n",
    "                                first_centroid = first_service\n",
    "                                second_centroid = second_service            \n",
    "                                break\n",
    "                        elif second_service in service_affinities:\n",
    "                            if first_service in service_affinities[second_service]:\n",
    "                                if min_affinity > float(service_affinities[second_service][first_service]):\n",
    "                                    min_affinity = float(service_affinities[second_service][first_service])\n",
    "                                    first_centroid = first_service\n",
    "                                    second_centroid = second_service\n",
    "                            else:\n",
    "                                # They dont have an affinity so pick them for centroids\n",
    "                                centroids_found = True\n",
    "                                first_centroid = first_service\n",
    "                                second_centroid = second_service            \n",
    "                                break\n",
    "                        else:\n",
    "                             # They dont have an affinity so pick them for centroids\n",
    "                            centroids_found = True\n",
    "                            first_centroid = first_service\n",
    "                            second_centroid = second_service            \n",
    "                            break            \n",
    "                \n",
    "                # Check if centroids have been found\n",
    "                if centroids_found:\n",
    "                    break\n",
    "                                                         \n",
    "            parent_cluster.remove(first_centroid)\n",
    "            parent_cluster.remove(second_centroid)\n",
    "            \n",
    "                        \n",
    "        print(\"---------\")\n",
    "        print(first_centroid)\n",
    "        print(second_centroid)\n",
    "\n",
    "        # Create Lists for centroids\n",
    "        app_clusters[last_index] = [first_centroid]\n",
    "        app_clusters[last_index + 1] = [second_centroid]\n",
    "\n",
    "\n",
    "        sum_affinity_centroid_1 = 0.0\n",
    "        sum_affinity_centroid_2 = 0.0\n",
    "        # Insert services to the random generated centroids\n",
    "        while parent_cluster:\n",
    "            curr_service = parent_cluster.pop(len(parent_cluster) - 1)\n",
    "            affinity_centroid_1 = 0.0\n",
    "            affinity_centroid_2 = 0.0\n",
    "\n",
    "            # Check if service belongs to keys of service_affinities dictionary\n",
    "            if curr_service in service_affinities:\n",
    "                # Check the affinities with centroids\n",
    "                if first_centroid in service_affinities[curr_service]:\n",
    "                    affinity_centroid_1 += float(service_affinities[curr_service][first_centroid])\n",
    "                elif second_centroid in service_affinities[curr_service]:\n",
    "                    affinity_centroid_2 += float(service_affinities[curr_service][second_centroid])\n",
    "\n",
    "            # Check if centroids contain the current service\n",
    "            if first_centroid in service_affinities:\n",
    "                if curr_service in service_affinities[first_centroid]:\n",
    "                    affinity_centroid_1 += float(service_affinities[first_centroid][curr_service])\n",
    "\n",
    "            if second_centroid in service_affinities:\n",
    "                if curr_service in service_affinities[second_centroid]:\n",
    "                    affinity_centroid_2 += float(service_affinities[second_centroid][curr_service])\n",
    "\n",
    "\n",
    "            # Assign service the best centroid according to max affinity\n",
    "            sum_affinity_centroid_1 += affinity_centroid_1\n",
    "            sum_affinity_centroid_2 += affinity_centroid_2\n",
    "            if affinity_centroid_1 < sum_affinity_centroid_2:\n",
    "                app_clusters[last_index + 1].append(curr_service)\n",
    "            elif affinity_centroid_1 > sum_affinity_centroid_2: \n",
    "                app_clusters[last_index].append(curr_service)\n",
    "            else:\n",
    "                app_clusters[random.choice([last_index, last_index+1])].append(curr_service)\n",
    "\n",
    "        # Update total affinities\n",
    "        cluster_affinities[last_index] = sum_affinity_centroid_1\n",
    "        cluster_affinities[last_index + 1] = sum_affinity_centroid_2\n",
    "\n",
    "        # Update variables\n",
    "        last_index += 2\n",
    "        cluster_count += 1\n",
    "        \n",
    "    return app_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(service_affinities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_partition = bisecting_k_means(service_list,service_affinities)\n",
    "app_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in service_list:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
